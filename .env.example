# Project Chimera - Environment Configuration

# ============================================
# LLM Configuration (DeepSeek)
# ============================================
DEEPSEEK_API_KEY=sk-your-api-key-here
DEEPSEEK_BASE_URL=https://api.deepseek.com
DEEPSEEK_MODEL=deepseek-chat
# Optional: Use different model for orchestrator reasoning
DEEPSEEK_ORCHESTRATOR_MODEL=deepseek-chat
# Timeout for LLM API calls (seconds)
LLM_TIMEOUT=30
# Max retries for failed LLM calls
LLM_MAX_RETRIES=3

# ============================================
# RabbitMQ Configuration
# ============================================
RABBITMQ_HOST=rabbitmq
RABBITMQ_PORT=5672
RABBITMQ_USER=guest
RABBITMQ_PASSWORD=guest
RABBITMQ_VHOST=/
RABBITMQ_MANAGEMENT_PORT=15672
# Connection retry settings
RABBITMQ_MAX_RETRIES=5
RABBITMQ_RETRY_DELAY=5

# ============================================
# Orchestrator Configuration
# ============================================
# Maximum time for entire orchestration (seconds)
ORCHESTRATOR_TIMEOUT=300
# Maximum time to wait for agent task (seconds)
AGENT_TASK_TIMEOUT=120
# ReAct loop max iterations (safety limit)
REACT_MAX_ITERATIONS=20

# ============================================
# Agent Configuration
# ============================================
# Agent versions
AGENT_VERSION=1.0.0
# Agent registration retry settings
AGENT_REGISTRATION_RETRIES=3
AGENT_REGISTRATION_DELAY=5

# ============================================
# API Service Configuration
# ============================================
API_HOST=0.0.0.0
API_PORT=8000
# Enable CORS for development
API_CORS_ENABLED=true
API_CORS_ORIGINS=*
# WebSocket configuration
WEBSOCKET_ENABLED=true
WEBSOCKET_PING_INTERVAL=30
WEBSOCKET_PING_TIMEOUT=10

# ============================================
# Data Paths (Docker volumes)
# ============================================
DATA_DIR=/app/data
OUTPUT_DIR=/app/output
# Log file paths
LOGS_DIR=/app/logs

# ============================================
# Logging Configuration
# ============================================
LOG_LEVEL=INFO
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FORMAT=json
# Options: json, text
LOG_OUTPUT=stdout
# Options: stdout, file, both

# ============================================
# Development / Debug Settings
# ============================================
DEBUG_MODE=false
# Enable verbose logging for RabbitMQ
RABBITMQ_DEBUG=false
# Enable LLM request/response logging
LLM_DEBUG=false
# Mock LLM calls (for testing without API costs)
MOCK_LLM=false

# ============================================
# Demo Configuration
# ============================================
DEMO_LOGS_FILE=sample_logs.json
# Auto-run demo on startup (for testing)
AUTO_RUN_DEMO=false

# ============================================
# Performance Tuning
# ============================================
# RabbitMQ prefetch count (messages per consumer)
RABBITMQ_PREFETCH_COUNT=1
# Agent worker pool size
AGENT_WORKERS=1
# Max concurrent orchestrations
MAX_CONCURRENT_ORCHESTRATIONS=5

# ============================================
# Monitoring & Observability
# ============================================
# Enable Prometheus metrics
METRICS_ENABLED=false
METRICS_PORT=9090
# Enable distributed tracing
TRACING_ENABLED=false
# OpenTelemetry endpoint
OTEL_EXPORTER_ENDPOINT=http://jaeger:4317
